diff --git a/scripts/torch/verify.py b/scripts/torch/verify.py
index ec96fa0..9d947f1 100644
--- a/scripts/torch/verify.py
+++ b/scripts/torch/verify.py
@@ -11,6 +11,7 @@ from __future__ import print_function
 import os
 import argparse
 from tqdm import tqdm
+import time
 
 import torch
 import torch.nn as nn
@@ -48,6 +49,18 @@ class Options():
                             help='put the path to resuming file if needed')
         parser.add_argument('--verify', type=str, default=None,
                             help='put the path to resuming file if needed')
+        parser.add_argument('--ipex', action='store_true', default=False,
+                    help='use ipex')
+        parser.add_argument('--jit', action='store_true', default=False,
+                            help='use ipex')
+        parser.add_argument('--precision', default="float32",
+                                help='precision, "float32" or "bfloat16"')
+        parser.add_argument('--warmup', type=int, default=10,
+                            help='number of warmup')
+        parser.add_argument('--max_iters', type=int, default=500,
+                            help='max number of iterations to run')
+        parser.add_argument('--dummy', action='store_true', default=False,
+                            help='use dummy data')
         self.parser = parser
 
     def parse(self):
@@ -58,31 +71,41 @@ class Options():
 def main():
     # init the args
     args = Options().parse()
+
+    if args.ipex:
+        import intel_pytorch_extension as ipex
+        print("Running with IPEX...")
+        if args.precision == "bfloat16":
+            # Automatically mix precision
+            ipex.enable_auto_mixed_precision(mixed_dtype=torch.bfloat16)
+            print('Running with bfloat16...')
+
     args.cuda = not args.no_cuda and torch.cuda.is_available()
     print(args)
     torch.manual_seed(args.seed)
     if args.cuda:
         torch.cuda.manual_seed(args.seed)
-    # init dataloader
-    interp = PIL.Image.BILINEAR if args.crop_size < 320 else PIL.Image.BICUBIC
-    base_size = args.base_size if args.base_size is not None else int(1.0 * args.crop_size / 0.875)
-    transform_val = transforms.Compose([
-        ECenterCrop(args.crop_size),
-        transforms.ToTensor(),
-        transforms.Normalize(mean=[0.485, 0.456, 0.406],
-                             std=[0.229, 0.224, 0.225]),
-    ])
-    valset = ImageNetDataset(transform=transform_val, train=False)
-    val_loader = torch.utils.data.DataLoader(
-        valset, batch_size=args.batch_size, shuffle=False,
-        num_workers=args.workers, pin_memory=True if args.cuda else False)
+    if not args.dummy:
+        # init dataloader
+        interp = PIL.Image.BILINEAR if args.crop_size < 320 else PIL.Image.BICUBIC
+        base_size = args.base_size if args.base_size is not None else int(1.0 * args.crop_size / 0.875)
+        transform_val = transforms.Compose([
+            ECenterCrop(args.crop_size),
+            transforms.ToTensor(),
+            transforms.Normalize(mean=[0.485, 0.456, 0.406],
+                                 std=[0.229, 0.224, 0.225]),
+        ])
+        valset = ImageNetDataset(transform=transform_val, train=False)
+        val_loader = torch.utils.data.DataLoader(
+            valset, batch_size=args.batch_size, shuffle=False,
+            num_workers=args.workers, pin_memory=True if args.cuda else False)
     
     # init the model
     model_kwargs = {}
 
-    assert args.model in torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)
-    model = torch.hub.load('zhanghang1989/ResNeSt', args.model, pretrained=True)
-    print(model)
+    assert args.model in torch.hub.list('zhanghang1989/ResNeSt', force_reload=False)
+    model = torch.hub.load('zhanghang1989/ResNeSt', args.model, pretrained=False)
+    # print(model)
 
     if args.cuda:
         model.cuda()
@@ -107,22 +130,68 @@ def main():
                 format(args.resume))
 
     model.eval()
+
+    if args.ipex:
+        model.to(ipex.DEVICE)
+        if args.jit:
+            data = torch.randn(args.batch_size, 3, args.crop_size, args.crop_size)
+            model = torch.jit.trace(model, data.to(ipex.DEVICE))
+
     top1 = AverageMeter()
     top5 = AverageMeter()
+    batch_time = AverageMeter()
     is_best = False
-    tbar = tqdm(val_loader, desc='\r')
-    for batch_idx, (data, target) in enumerate(tbar):
-        if args.cuda:
-            data, target = data.cuda(), target.cuda()
-        with torch.no_grad():
-            output = model(data)
-            acc1, acc5 = accuracy(output, target, topk=(1, 5))
-            top1.update(acc1[0], data.size(0))
-            top5.update(acc5[0], data.size(0))
+    if args.dummy:
+        max_iters = args.max_iters + args.warmup
+        for batch_idx in range(max_iters):
+            data = torch.randn(args.batch_size, 3, args.crop_size, args.crop_size)
+            target = torch.arange(1, args.batch_size + 1).long()
+            if batch_idx >= args.warmup:
+                start = time.time()
+            if args.ipex:
+                data, target = data.to(ipex.DEVICE), target.to(ipex.DEVICE)
+            elif args.cuda:
+                data, target = data.cuda(), target.cuda()
+
+            with torch.no_grad():
+                output = model(data)
+            if batch_idx >= args.warmup:
+                batch_time.update(time.time() - start)
+
+            if batch_idx % 10 == 0:
+                print('iters: {:d}/{:d}, {:0.3f}({:0.3f}).'.format(batch_idx + 1, max_iters, batch_time.val, batch_time.avg))
+
+            if batch_idx >= max_iters -1:
+                break
+    else:
+        tbar = tqdm(val_loader, desc='\r')
+        max_iters = min(args.max_iters + args.warmup, len(tbar)) if args.max_iters > 0 else len(tbar)
+        for batch_idx, (data, target) in enumerate(tbar):
+            if batch_idx >= args.warmup:
+                start = time.time()
+            if args.ipex:
+                data, target = data.to(ipex.DEVICE), target.to(ipex.DEVICE)
+            elif args.cuda:
+                data, target = data.cuda(), target.cuda()
+
+            with torch.no_grad():
+                output = model(data)
+                acc1, acc5 = accuracy(output, target, topk=(1, 5))
+                top1.update(acc1[0], data.size(0))
+                top5.update(acc5[0], data.size(0))
+            if batch_idx >= args.warmup:
+                batch_time.update(time.time() - start)
+
+            tbar.set_description('Top1: %.3f | Top5: %.3f'%(top1.avg, top5.avg))
 
-        tbar.set_description('Top1: %.3f | Top5: %.3f'%(top1.avg, top5.avg))
+            if batch_idx >= max_iters -1:
+                break
 
-    print('Top1 Acc: %.3f | Top5 Acc: %.3f '%(top1.avg, top5.avg))
+        print('Top1 Acc: %.3f | Top5 Acc: %.3f '%(top1.avg, top5.avg))
+    latency = batch_time.avg / args.batch_size * 1000
+    perf = args.batch_size / batch_time.avg
+    print('inference latency: %0.3f ms' % latency)
+    print('inference Throughput: %0.3f fps' % perf)
 
 class ECenterCrop:
     """Crop the given PIL Image and resize it to desired size.
@@ -179,12 +248,12 @@ class AverageMeter(object):
         self.reset()
 
     def reset(self):
-        #self.val = 0
+        self.val = 0
         self.sum = 0
         self.count = 0
 
     def update(self, val, n=1):
-        #self.val = val
+        self.val = val
         self.sum += val * n
         self.count += n
 
